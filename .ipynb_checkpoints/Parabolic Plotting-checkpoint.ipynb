{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Memory growth must be set at program startup",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d6ebfe4ebf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\config.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[1;34m(device, enable)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[0menable\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0menable\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdisable\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0mgrowth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m   \"\"\"\n\u001b[1;32m--> 454\u001b[1;33m   \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[1;34m(self, dev, enable)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;34m\"\"\"Set if memory growth should be enabled for a PhysicalDevice.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Memory growth must be set at program startup\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Memory growth must be set at program startup"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import harmonic_distance as hd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant(0.2, dtype=tf.float64)\n",
    "n_points = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0623 09:28:40.059231 34440 deprecation.py:323] From C:\\Users\\andrewcsmith\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1340: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratios: \t [1.         1.125      1.33333333 1.5        2.        ]\n",
      "Log-2 Ratios: \t [0.        0.169925  0.4150375 0.5849625 1.       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=107, shape=(5, 2), dtype=float64, numpy=\n",
       "array([[-3.,  2.],\n",
       "       [-1.,  1.],\n",
       "       [ 0.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 2., -1.]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're just calculating the unison, fourth, fifth, octave\n",
    "@tf.function\n",
    "def get_vectors():\n",
    "    return hd.vectors.space_graph(2, 3, bounds=(0.0, 1.0))\n",
    "vecs = get_vectors()\n",
    "ratios = np.sort(np.prod(hd.PRIMES[:vecs.shape[-1]] ** vecs, axis=1))\n",
    "# Print out the logs of the vectors\n",
    "print(\"Ratios: \\t\", ratios)\n",
    "print(\"Log-2 Ratios: \\t\", np.log2(ratios))\n",
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor for the permutations of unison, fourth, fifth, octave\n",
    "@tf.function\n",
    "def get_perms():\n",
    "    return hd.cartesian.permutations(vecs, times=2)\n",
    "perms = get_perms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(2, 2), b.shape=(2, 3), m=2, n=3, k=2 [Op:MatMul] name: map/while/Tensordot/MatMul/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bab30778fd90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtenney\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_aggregate_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtenney\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhd_aggregate_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\andrewcsmith\\workspaces\\music\\tf-harmonic-distance\\harmonic_distance\\harmonic_distance\\tenney.py\u001b[0m in \u001b[0;36mhd_aggregate_graph\u001b[1;34m(aggregates)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mhds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexploded_hd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maggregates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_hd_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpd_aggregate_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maggregates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[1;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         maximum_iterations=n)\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2688\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2689\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   2681\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 2682\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\map_fn.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(i, tas)\u001b[0m\n\u001b[0;32m    255\u001b[0m       \"\"\"\n\u001b[0;32m    256\u001b[0m       \u001b[0mpacked_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m       \u001b[0mpacked_fn_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m       \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacked_fn_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m       \u001b[0mflat_fn_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_fn_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrewcsmith\\workspaces\\music\\tf-harmonic-distance\\harmonic_distance\\harmonic_distance\\tenney.py\u001b[0m in \u001b[0;36mget_hd_sum\u001b[1;34m(hd)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_hd_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes, name)\u001b[0m\n\u001b[0;32m   3862\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[0;32m   3863\u001b[0m         b, b_axes, True)\n\u001b[1;32m-> 3864\u001b[1;33m     \u001b[0mab_matmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3865\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3866\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mab_matmul\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_free_dims\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_free_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2646\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2647\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6283\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6284\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6285\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6286\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6287\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(2, 2), b.shape=(2, 3), m=2, n=3, k=2 [Op:MatMul] name: map/while/Tensordot/MatMul/"
     ]
    }
   ],
   "source": [
    "pds = hd.tenney.pd_aggregate_graph(perms)\n",
    "hds = hd.tenney.hd_aggregate_graph(perms) + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"default\", reuse=tf.AUTO_REUSE):\n",
    "    log_pitches = tf.get_variable(\"log_pitches\", [n_points, 2], dtype=tf.float64)\n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0.0, 1.0, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_calc(pds, hds, log_pitches, a=1.0, b=1.0):\n",
    "    \"\"\"\n",
    "    pds: Pitch distance coordinate values of each vector in the space\n",
    "    hds: Aggregate harmonic distance values of each vector in the space\n",
    "    log_pitches: The set of pitches to evaluate\n",
    "    \"\"\"\n",
    "    distances = tf.map_fn(lambda x: hd.utilities.reduce_parabola(pds - x, a=a, b=b), log_pitches)\n",
    "    return tf.reduce_min(distances * hds + hds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_coords_and_return(slice_level, a=1.0, b=1.0):\n",
    "    \"\"\"\n",
    "    Given a y-level (in a 2-dimensional space), take a slice of it with a xs.\n",
    "    \"\"\"\n",
    "    xy_coords = np.hstack([xs[:, None], np.full_like(xs, slice_level)[:, None]])\n",
    "    z_op = z_calc(pds, hds, tf.constant(xy_coords, dtype=tf.float64), a=a, b=b)\n",
    "    zs = sess.run(z_op)\n",
    "    plt.ylim(0.0, 30.0)\n",
    "    for x in sess.run(pds):\n",
    "        plt.axvline(x=x[0])\n",
    "    plt.plot(xs, zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assign_coords_and_return(np.log2(3.0), a=C, b=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-dimensional optimization\n",
    "\n",
    "Setting out the batch sizes, etc.\n",
    "\n",
    "We're reusing the vectors etc. from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.02\n",
    "LEARNING_RATE = 1.0e-3\n",
    "CONVERGENCE_THRESHOLD = 1.0e-8\n",
    "MAX_ITERS = 1000000\n",
    "DIMENSIONS = 2\n",
    "BATCH_SIZE = 512\n",
    "POINTS_PER_DIMENSION = 64\n",
    "xs = np.linspace(0.00, 1.0, POINTS_PER_DIMENSION)\n",
    "ys = np.linspace(0.00, 1.0, POINTS_PER_DIMENSION)\n",
    "xv, yv = np.meshgrid(xs, ys, sparse=False)\n",
    "zv = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"2d_optimization\", reuse=tf.AUTO_REUSE):\n",
    "    log_pitches = tf.get_variable(\"log_pitches_64x512\", [BATCH_SIZE, DIMENSIONS], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = z_calc(pds, hds, log_pitches, a=C, b=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_op = hd.optimize.stopping_op(loss, [log_pitches], lr=LEARNING_RATE, ct=CONVERGENCE_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a vector of pairs of shape [n_points**dimensions, dimensions]\n",
    "starting_coordinates = np.array([xv, yv]).reshape(DIMENSIONS, POINTS_PER_DIMENSION**DIMENSIONS).T\n",
    "starting_dataset = tf.data.Dataset.from_tensor_slices({\n",
    "    \"coords\": tf.constant(starting_coordinates)\n",
    "})\n",
    "starting_iterator = starting_dataset.batch(BATCH_SIZE).make_one_shot_iterator()\n",
    "next_element = starting_iterator.get_next()\n",
    "assign_op = log_pitches.assign(next_element['coords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_pitches_log = np.empty([0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration:  184\n",
      "Converged at iteration:  209\n",
      "Converged at iteration:  216\n",
      "Converged at iteration:  211\n",
      "Converged at iteration:  199\n",
      "Converged at iteration:  207\n",
      "Converged at iteration:  201\n",
      "Converged at iteration:  187\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        sess.run([assign_op])\n",
    "        for idx in range(MAX_ITERS):\n",
    "            if (sess.run(stopping_op)):\n",
    "                print(\"Converged at iteration: \", idx)\n",
    "                out_pitches = np.array(sess.run(log_pitches))\n",
    "                all_possible_pitches_log = np.concatenate([all_possible_pitches_log, out_pitches])\n",
    "                break\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00],\n",
       "       [1.87200106e-20, 0.00000000e+00],\n",
       "       [3.74400212e-20, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_possible_pitches_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 2)\n",
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [1.87200106e-20 0.00000000e+00]\n",
      " [3.74400212e-20 0.00000000e+00]\n",
      " ...\n",
      " [1.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 1.00000000e+00]]\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [1. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [1. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0.]\n",
      "  [1. 0. 0.]]]\n",
      "20\n",
      "[((1.0, 1.0), (1.0, 1.0)), ((1.0, 1.0), (5.0, 4.0)), ((1.0, 1.0), (4.0, 3.0)), ((1.0, 1.0), (3.0, 2.0)), ((1.0, 1.0), (5.0, 3.0)), ((1.0, 1.0), (2.0, 1.0)), ((5.0, 4.0), (1.0, 1.0)), ((5.0, 4.0), (5.0, 4.0)), ((4.0, 3.0), (1.0, 1.0)), ((4.0, 3.0), (4.0, 3.0)), ((4.0, 3.0), (2.0, 1.0)), ((3.0, 2.0), (1.0, 1.0)), ((3.0, 2.0), (3.0, 2.0)), ((3.0, 2.0), (2.0, 1.0)), ((5.0, 3.0), (1.0, 1.0)), ((5.0, 3.0), (5.0, 3.0)), ((2.0, 1.0), (1.0, 1.0)), ((2.0, 1.0), (4.0, 3.0)), ((2.0, 1.0), (3.0, 2.0)), ((2.0, 1.0), (2.0, 1.0))]\n"
     ]
    }
   ],
   "source": [
    "print(all_possible_pitches_log.shape)\n",
    "log_vectors = hd.vectors.pd_graph(vectors)\n",
    "\n",
    "print(all_possible_pitches_log)\n",
    "diffs_to_poles = tf.abs(tf.tile(log_vectors[:, None, None], [1, 1, 2]) - all_possible_pitches_log)\n",
    "mins = tf.argmin(diffs_to_poles, axis=0)\n",
    "winner = tf.map_fn(lambda m: tf.map_fn(lambda v: vectors[v], m, dtype=tf.float64), mins, dtype=tf.float64)\n",
    "winners = sess.run(winner)\n",
    "print(winners)\n",
    "\n",
    "def vector_to_ratio(vector):\n",
    "    primes = hd.PRIMES[:vector.shape[0]]\n",
    "    num = np.where(vector > 0, vector, np.zeros_like(primes))\n",
    "    den = np.where(vector < 0, vector, np.zeros_like(primes))\n",
    "    return (\n",
    "        np.product(np.power(primes, num)), \n",
    "        np.product(primes ** np.abs(den))\n",
    "    )\n",
    "\n",
    "all_possible_pitches = set()\n",
    "\n",
    "for row in winners:\n",
    "    all_possible_pitches.add(tuple([vector_to_ratio(r) for r in row]))\n",
    "\n",
    "print(len(all_possible_pitches))\n",
    "print(sorted(all_possible_pitches, key=lambda r: (r[0][0] / r[0][1], r[1][0] / r[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
